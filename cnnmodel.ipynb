{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","# NOTE: Make a shortcut to APS360 Project folder in your MyDrive\n","DATA_PATH = '/content/drive/MyDrive/APS360 Project/vegetable dataset'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lQkm3wgRPYZT","executionInfo":{"status":"ok","timestamp":1680720090189,"user_tz":240,"elapsed":24913,"user":{"displayName":"Krishna Patel","userId":"00874990611338542518"}},"outputId":"9d64c484-c66e-4e65-f1d8-be23b4084a3f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","from torchvision import datasets, transforms\n","import matplotlib.pyplot as plt # for plotting\n","\n","import torch.optim as optim\n","\n","training_set_path = DATA_PATH + '/training'\n","validation_set_path = DATA_PATH + '/validation'\n","test_set_path = DATA_PATH + '/test'\n","\n","\n","# Transform Settings\n","data_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(\n","        mean=[0.5, 0.5, 0.5],\n","        std=[0.5, 0.5, 0.5]\n","    )\n","])\n","training_dataset = datasets.ImageFolder(training_set_path, transform=data_transform)\n","validation_dataset = datasets.ImageFolder(validation_set_path, transform=data_transform)\n","test_dataset = datasets.ImageFolder(test_set_path, transform=data_transform)\n","\n","print(\"Number of training images:\", len(training_dataset))\n","print(\"Number of validation images:\", len(validation_dataset))\n","print(\"Number of test images:\", len(test_dataset))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pnkR_tFtXySY","executionInfo":{"status":"ok","timestamp":1680720145587,"user_tz":240,"elapsed":17536,"user":{"displayName":"Krishna Patel","userId":"00874990611338542518"}},"outputId":"2bb9d731-8f8f-45a7-dfc9-655b65189bb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training images: 2016\n","Number of validation images: 677\n","Number of test images: 716\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j1yqx1NbElZw","outputId":"8f74e267-81a7-46d0-a90f-e06a8fc70fb4","executionInfo":{"status":"ok","timestamp":1680720116892,"user_tz":240,"elapsed":7086,"user":{"displayName":"Krishna Patel","userId":"00874990611338542518"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n","100%|██████████| 233M/233M [00:00<00:00, 285MB/s]\n"]}],"source":["import torchvision.models\n","alexnet = torchvision.models.alexnet(pretrained=True).cuda()"]},{"cell_type":"code","source":["import os\n","from torch.utils.data.dataloader import DataLoader\n","useCuda = True\n","\n","train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=1, shuffle=True)\n","validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=1, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n","\n","FEATURE_PATH = '/content/drive/MyDrive/APS360 Project/alexnet'\n","\n","classes = [\n","    'asparagus',\n","    'bell pepper',\n","    'broccoli',\n","    'cabbage',\n","    'carrot',\n","    'celery',\n","    'chilli pepper',\n","    'corn',\n","    'cucumber',\n","    'eggplant',\n","    'lettuce',\n","    'mushroom',\n","    'onion',\n","    'peas',\n","    'potato',\n","    'pumpkin',\n","    'raddish',\n","    'spinach',\n","    'sweet potato',\n","    'tomato'\n","]\n","\n","training_feature_path = FEATURE_PATH + '/training/'\n","validation_feature_path = FEATURE_PATH + '/validation/'\n","test_feature_path = FEATURE_PATH + '/test/'\n","\n","n=0\n","for img, label in train_loader:\n","  features = alexnet.features(img.cuda())\n","  tensor = torch.from_numpy(features.detach().cpu().numpy())\n","  torch.save(tensor.squeeze(0), training_feature_path + str(classes[label.cuda()]) + '/' + str(n) + '.tensor')\n","  n+=1\n","\n","n=0\n","for img, label in validation_loader:\n","  features = alexnet.features(img.cuda())\n","  tensor = torch.from_numpy(features.detach().cpu().numpy())\n","  torch.save(tensor.squeeze(0), validation_feature_path + str(classes[label.cuda()]) + '/' + str(n) + '.tensor')\n","  n+=1\n","\n","\n","n=0\n","for img, label in test_loader:\n","  features = alexnet.features(img.cuda())\n","  tensor = torch.from_numpy(features.detach().cpu().numpy())\n","  torch.save(tensor.squeeze(0), test_feature_path + str(classes[label.cuda()]) + '/' + str(n) + '.tensor')\n","  n+=1\n","\n"],"metadata":{"id":"ON_EIYph4ioC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AlexNetCNN(nn.Module):\n","    def __init__(self):\n","        super(AlexNetCNN, self).__init__()\n","        self.name = \"AlexNetCNN\"\n","        self.conv1 = nn.Conv2d(256, 256, 5)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(256 * 1 * 1, 20)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = x.view(-1, 256 * 1 * 1)\n","        x = self.fc1(x)\n","        return x"],"metadata":{"id":"_tZJV5DZgqWU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["FEATURE_PATH = '/content/drive/MyDrive/APS360 Project/alexnet'\n","\n","training_feature_path = FEATURE_PATH + '/training'\n","validation_feature_path = FEATURE_PATH + '/validation'\n","test_feature_path = FEATURE_PATH + '/test'\n","\n","\n","training_features = torchvision.datasets.DatasetFolder(training_feature_path, loader=torch.load, extensions=('.tensor'))\n","\n","validation_features = torchvision.datasets.DatasetFolder(validation_feature_path, loader=torch.load, extensions=('.tensor'))\n","\n","test_features = torchvision.datasets.DatasetFolder(test_feature_path, loader=torch.load, extensions=('.tensor'))"],"metadata":{"id":"PJxAEBd9h3nq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_accuracy_alex(model, train_loader, valid_loader, train=False):\n","    use_cuda = True\n","    if train:\n","        data = train_loader\n","    else:\n","        data = valid_loader\n","\n","    correct = 0\n","    total = 0\n","    for imgs, labels in data:    \n","        #############################################\n","        #To Enable GPU Usage\n","        if use_cuda and torch.cuda.is_available():\n","          imgs = imgs.cuda()\n","          labels = labels.cuda()\n","        #############################################\n","        \n","        \n","        output = model(imgs)\n","        \n","        #select index with maximum prediction score\n","        pred = output.max(1, keepdim=True)[1]\n","        correct += pred.eq(labels.view_as(pred)).sum().item()\n","        total += imgs.shape[0]\n","    return correct / total"],"metadata":{"id":"a8g-KxRNjAut"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_alex(model, train_dataset, valid_dataset, batch_size=64, learning_rate=0.001, num_epochs=1):\n","    # Prepare Dataloader\n","    use_cuda = True\n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)     \n","\n","    criterion = nn.CrossEntropyLoss()\n","    #optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    iters, losses, train_acc, val_acc = [], [], [], []\n","\n","    # training\n","    epoch = 0 # the number of iterations\n","    for epoch in range(num_epochs):\n","        for features, labels in iter(train_loader):\n","          \n","            #############################################\n","            #To Enable GPU Usage\n","            if use_cuda and torch.cuda.is_available():\n","              features = features.cuda()\n","              labels = labels.cuda()\n","            #############################################\n","            \n","            \n","            out = model(features)      # forward pass\n","            loss = criterion(out, labels) # compute the total loss\n","            loss.backward()               # backward pass (compute parameter updates)\n","            optimizer.step()              # make the updates for each parameter\n","            optimizer.zero_grad()         # a clean up step for PyTorch\n","\n","\n","        # save the current training information\n","        iters.append(epoch)\n","        losses.append(float(loss)/batch_size)             # compute *average* loss\n","        train_acc.append(get_accuracy_alex(model, train_loader, valid_loader, train=True)) # compute training accuracy\n","        val_acc.append(get_accuracy_alex(model, train_loader, valid_loader, train=False))  # compute validation accuracy\n","        print((\"Epoch {}: Train acc: {} |\"+\"Validation acc: {}\").format(epoch + 1,train_acc[-1],val_acc[-1]))\n","        torch.save(model.state_dict(), \"saved_model\")\n","      \n","    # plotting\n","    plt.title(\"Training Curve\")\n","    plt.plot(iters, losses, label=\"Train\")\n","    plt.xlabel(\"Iterations\") \n","    plt.ylabel(\"Loss\")\n","    plt.show()\n","\n","    plt.title(\"Training Curve\")\n","    plt.plot(iters, train_acc, label=\"Train\")\n","    plt.plot(iters, val_acc, label=\"Validation\")\n","    plt.xlabel(\"Iterations\")\n","    plt.ylabel(\"Training Accuracy\") \n","    plt.legend(loc='best')\n","    plt.show()\n","\n","    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n","    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))"],"metadata":{"id":"XexsMfqAjB4e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_alex_model = AlexNetCNN()\n","\n","best_alex_model.cuda()\n","\n","train_alex(best_alex_model, training_features, validation_features, learning_rate=0.0001, batch_size=128, num_epochs=39)"],"metadata":{"id":"gO769pabncCG","colab":{"base_uri":"https://localhost:8080/","height":346},"executionInfo":{"status":"error","timestamp":1680720566600,"user_tz":240,"elapsed":148547,"user":{"displayName":"Krishna Patel","userId":"00874990611338542518"}},"outputId":"6986f4f7-7ea6-4eb1-dbd1-ff662067f6b2"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-9b851051104c>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_alex_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_alex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_alex_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m39\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-f39efeb20366>\u001b[0m in \u001b[0;36mtrain_alex\u001b[0;34m(model, train_dataset, valid_dataset, batch_size, learning_rate, num_epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# the number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m#############################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \"\"\"\n\u001b[1;32m    228\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0;31m# If we want to actually tail call to torch.jit.load, we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_is_zipfile\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mbyte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mbyte\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mread_bytes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from google.colab import files\n","\n","# Download the saved model file \n","files.download('saved_model')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"LYdIrbjeJ5QE","executionInfo":{"status":"ok","timestamp":1680543656210,"user_tz":240,"elapsed":168,"user":{"displayName":"Krishna Patel","userId":"00874990611338542518"}},"outputId":"5d40cc56-531e-4ec2-c265-044997f67785"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_2867ced0-f12d-4817-952b-d64d987d1c51\", \"saved_model\", 6576887)"]},"metadata":{}}]},{"cell_type":"code","source":["test_loader =  torch.utils.data.DataLoader(test_features, batch_size=128, shuffle=True) \n","test_accuracy = get_accuracy_alex(best_alex_model, train_loader, test_loader, train=False)\n","print('Test accuracy: ', test_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ttAL3aUjDHL6","executionInfo":{"status":"ok","timestamp":1680562259610,"user_tz":240,"elapsed":1444,"user":{"displayName":"Krishna Patel","userId":"00874990611338542518"}},"outputId":"933acf8f-9550-44aa-d5d8-3e4d276c9760"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy:  0.4781382228490832\n"]}]}]}